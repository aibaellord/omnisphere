#!/usr/bin/env python3
"""
üìä REAL YOUTUBE DATA COLLECTOR üìä
Actual working implementation for collecting YouTube data and analytics

This is a functional system that uses real APIs to gather actionable data
for content creation and competitor analysis.
"""

import os
import time
import json
import logging
import sqlite3
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
import googleapiclient.discovery
import googleapiclient.errors
from textblob import TextBlob
import requests
import pandas as pd
import numpy as np
from collections import defaultdict

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class VideoData:
    """Real video data structure"""
    video_id: str
    title: str
    channel_id: str
    channel_title: str
    published_at: str
    duration: str
    view_count: int
    like_count: int
    comment_count: int
    tags: List[str]
    category_id: str
    description: str
    engagement_rate: float
    
    def to_dict(self) -> Dict:
        return asdict(self)

@dataclass
class ChannelData:
    """Real channel data structure"""
    channel_id: str
    title: str
    subscriber_count: int
    total_views: int
    video_count: int
    created_at: str
    avg_views_per_video: float
    growth_rate: float
    
    def to_dict(self) -> Dict:
        return asdict(self)

class RealYouTubeCollector:
    """
    üìà REAL YOUTUBE DATA COLLECTOR
    
    Actually working implementation that collects real data from YouTube API
    for competitive analysis and content optimization.
    """
    
    def __init__(self, api_key: str, db_path: str = "youtube_data.db"):
        self.api_key = api_key
        self.db_path = db_path
        
        # Initialize YouTube API client
        try:
            self.youtube = googleapiclient.discovery.build(
                'youtube', 'v3', 
                developerKey=api_key,
                cache_discovery=False
            )
            logger.info("‚úÖ YouTube API client initialized")
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize YouTube API: {e}")
            raise
        
        # Initialize database
        self._setup_database()
    
    def _setup_database(self):
        """Set up SQLite database for storing collected data"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Videos table
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS videos (
            video_id TEXT PRIMARY KEY,
            title TEXT,
            channel_id TEXT,
            channel_title TEXT,
            published_at TEXT,
            duration TEXT,
            view_count INTEGER,
            like_count INTEGER,
            comment_count INTEGER,
            tags TEXT,
            category_id TEXT,
            description TEXT,
            engagement_rate REAL,
            collected_at TEXT
        )
        ''')
        
        # Channels table
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS channels (
            channel_id TEXT PRIMARY KEY,
            title TEXT,
            subscriber_count INTEGER,
            total_views INTEGER,
            video_count INTEGER,
            created_at TEXT,
            avg_views_per_video REAL,
            growth_rate REAL,
            last_updated TEXT
        )
        ''')
        
        # Trends table
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS trends (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            keyword TEXT,
            trend_score REAL,
            category TEXT,
            detected_at TEXT
        )
        ''')
        
        conn.commit()
        conn.close()
        logger.info("‚úÖ Database initialized")
    
    def get_trending_videos(self, region_code: str = 'US', max_results: int = 50) -> List[VideoData]:
        """Get actual trending videos from YouTube"""
        try:
            request = self.youtube.videos().list(
                part='snippet,statistics,contentDetails',
                chart='mostPopular',
                regionCode=region_code,
                maxResults=max_results
            )
            
            response = request.execute()
            videos = []
            
            for item in response['items']:
                try:
                    snippet = item['snippet']
                    statistics = item['statistics']
                    content_details = item['contentDetails']
                    
                    # Calculate engagement rate
                    views = int(statistics.get('viewCount', 0))
                    likes = int(statistics.get('likeCount', 0))
                    comments = int(statistics.get('commentCount', 0))
                    
                    engagement_rate = ((likes + comments) / views * 100) if views > 0 else 0
                    
                    video = VideoData(
                        video_id=item['id'],
                        title=snippet['title'],
                        channel_id=snippet['channelId'],
                        channel_title=snippet['channelTitle'],
                        published_at=snippet['publishedAt'],
                        duration=content_details['duration'],
                        view_count=views,
                        like_count=likes,
                        comment_count=comments,
                        tags=snippet.get('tags', []),
                        category_id=snippet['categoryId'],
                        description=snippet.get('description', ''),
                        engagement_rate=engagement_rate
                    )
                    
                    videos.append(video)
                    
                except Exception as e:
                    logger.warning(f"Error processing video {item.get('id', 'unknown')}: {e}")
                    continue
            
            # Store in database
            self._store_videos(videos)
            
            logger.info(f"‚úÖ Collected {len(videos)} trending videos")
            return videos
            
        except Exception as e:
            logger.error(f"‚ùå Error getting trending videos: {e}")
            return []
    
    def analyze_channel(self, channel_id: str) -> Optional[ChannelData]:
        """Analyze a specific YouTube channel"""
        try:
            # Get channel details
            channel_request = self.youtube.channels().list(
                part='snippet,statistics',
                id=channel_id
            )
            
            channel_response = channel_request.execute()
            
            if not channel_response['items']:
                logger.warning(f"Channel {channel_id} not found")
                return None
            
            channel_item = channel_response['items'][0]
            snippet = channel_item['snippet']
            statistics = channel_item['statistics']
            
            subscriber_count = int(statistics.get('subscriberCount', 0))
            total_views = int(statistics.get('viewCount', 0))
            video_count = int(statistics.get('videoCount', 0))
            
            avg_views = total_views / video_count if video_count > 0 else 0
            
            # Get recent videos for growth analysis
            recent_videos = self._get_recent_channel_videos(channel_id)
            growth_rate = self._calculate_growth_rate(recent_videos)
            
            channel_data = ChannelData(
                channel_id=channel_id,
                title=snippet['title'],
                subscriber_count=subscriber_count,
                total_views=total_views,
                video_count=video_count,
                created_at=snippet['publishedAt'],
                avg_views_per_video=avg_views,
                growth_rate=growth_rate
            )
            
            # Store in database
            self._store_channel(channel_data)
            
            logger.info(f"‚úÖ Analyzed channel: {snippet['title']}")
            return channel_data
            
        except Exception as e:
            logger.error(f"‚ùå Error analyzing channel {channel_id}: {e}")
            return None
    
    def search_videos_by_keyword(self, keyword: str, max_results: int = 25) -> List[VideoData]:
        """Search for videos by keyword and analyze performance"""
        try:
            search_request = self.youtube.search().list(
                part='snippet',
                q=keyword,
                type='video',
                maxResults=max_results,
                order='relevance'
            )
            
            search_response = search_request.execute()
            video_ids = [item['id']['videoId'] for item in search_response['items']]
            
            # Get detailed video statistics
            videos_request = self.youtube.videos().list(
                part='snippet,statistics,contentDetails',
                id=','.join(video_ids)
            )
            
            videos_response = videos_request.execute()
            videos = []
            
            for item in videos_response['items']:
                try:
                    snippet = item['snippet']
                    statistics = item['statistics']
                    content_details = item['contentDetails']
                    
                    views = int(statistics.get('viewCount', 0))
                    likes = int(statistics.get('likeCount', 0))
                    comments = int(statistics.get('commentCount', 0))
                    
                    engagement_rate = ((likes + comments) / views * 100) if views > 0 else 0
                    
                    video = VideoData(
                        video_id=item['id'],
                        title=snippet['title'],
                        channel_id=snippet['channelId'],
                        channel_title=snippet['channelTitle'],
                        published_at=snippet['publishedAt'],
                        duration=content_details['duration'],
                        view_count=views,
                        like_count=likes,
                        comment_count=comments,
                        tags=snippet.get('tags', []),
                        category_id=snippet['categoryId'],
                        description=snippet.get('description', ''),
                        engagement_rate=engagement_rate
                    )
                    
                    videos.append(video)
                    
                except Exception as e:
                    logger.warning(f"Error processing video {item.get('id', 'unknown')}: {e}")
                    continue
            
            self._store_videos(videos)
            
            logger.info(f"‚úÖ Found {len(videos)} videos for keyword: {keyword}")
            return videos
            
        except Exception as e:
            logger.error(f"‚ùå Error searching videos for keyword {keyword}: {e}")
            return []
    
    def get_competitor_analysis(self, channel_ids: List[str]) -> Dict[str, Any]:
        """Perform competitive analysis on multiple channels"""
        competitors = []
        
        for channel_id in channel_ids:
            channel_data = self.analyze_channel(channel_id)
            if channel_data:
                competitors.append(channel_data)
            
            # Rate limiting
            time.sleep(0.5)
        
        if not competitors:
            return {}
        
        # Calculate competitive metrics
        avg_subscribers = np.mean([c.subscriber_count for c in competitors])
        avg_views = np.mean([c.avg_views_per_video for c in competitors])
        avg_growth = np.mean([c.growth_rate for c in competitors])
        
        # Find top performers
        top_by_subscribers = sorted(competitors, key=lambda x: x.subscriber_count, reverse=True)
        top_by_engagement = sorted(competitors, key=lambda x: x.growth_rate, reverse=True)
        
        analysis = {
            'total_competitors': len(competitors),
            'market_averages': {
                'subscribers': avg_subscribers,
                'avg_views_per_video': avg_views,
                'growth_rate': avg_growth
            },
            'top_performers': {
                'by_subscribers': [c.to_dict() for c in top_by_subscribers[:3]],
                'by_growth': [c.to_dict() for c in top_by_engagement[:3]]
            },
            'opportunities': self._identify_opportunities(competitors),
            'analysis_date': datetime.now().isoformat()
        }
        
        logger.info(f"‚úÖ Competitive analysis complete for {len(competitors)} channels")
        return analysis
    
    def detect_trending_topics(self, days_back: int = 7) -> List[Dict[str, Any]]:
        """Detect trending topics from recent video data"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            # Get videos from the last N days
            cutoff_date = (datetime.now() - timedelta(days=days_back)).isoformat()
            
            query = '''
            SELECT title, tags, view_count, engagement_rate 
            FROM videos 
            WHERE collected_at > ? 
            ORDER BY view_count DESC, engagement_rate DESC
            LIMIT 500
            '''
            
            df = pd.read_sql_query(query, conn, params=(cutoff_date,))
            conn.close()
            
            if df.empty:
                logger.warning("No recent video data found")
                return []
            
            # Extract keywords from titles and tags
            keyword_scores = defaultdict(float)
            
            for _, row in df.iterrows():
                title_words = row['title'].lower().split()
                tags = json.loads(row['tags']) if row['tags'] else []
                
                # Score keywords based on video performance
                performance_score = (row['view_count'] / 1000) + (row['engagement_rate'] * 10)
                
                for word in title_words + [tag.lower() for tag in tags]:
                    if len(word) > 3:  # Filter out short words
                        keyword_scores[word] += performance_score
            
            # Sort and format trending topics
            trending_topics = []
            for keyword, score in sorted(keyword_scores.items(), key=lambda x: x[1], reverse=True)[:20]:
                trending_topics.append({
                    'keyword': keyword,
                    'trend_score': score,
                    'category': 'general',
                    'detected_at': datetime.now().isoformat()
                })
            
            # Store trending topics
            self._store_trends(trending_topics)
            
            logger.info(f"‚úÖ Detected {len(trending_topics)} trending topics")
            return trending_topics
            
        except Exception as e:
            logger.error(f"‚ùå Error detecting trending topics: {e}")
            return []
    
    def _get_recent_channel_videos(self, channel_id: str, max_results: int = 10) -> List[Dict]:
        """Get recent videos from a channel for growth analysis"""
        try:
            search_request = self.youtube.search().list(
                part='snippet',
                channelId=channel_id,
                type='video',
                maxResults=max_results,
                order='date'
            )
            
            search_response = search_request.execute()
            return search_response['items']
            
        except Exception as e:
            logger.warning(f"Error getting recent videos for channel {channel_id}: {e}")
            return []
    
    def _calculate_growth_rate(self, recent_videos: List[Dict]) -> float:
        """Calculate growth rate based on recent video performance"""
        if not recent_videos:
            return 0.0
        
        # Simple growth rate calculation based on video recency
        # In a real implementation, you'd use more sophisticated metrics
        return len(recent_videos) * 10.0  # Placeholder calculation
    
    def _identify_opportunities(self, competitors: List[ChannelData]) -> List[Dict[str, Any]]:
        """Identify market opportunities based on competitor analysis"""
        opportunities = []
        
        if not competitors:
            return opportunities
        
        # Find gaps in content performance
        median_growth = np.median([c.growth_rate for c in competitors])
        median_views = np.median([c.avg_views_per_video for c in competitors])
        
        # Identify underperforming segments
        underperformers = [c for c in competitors if c.growth_rate < median_growth * 0.5]
        
        if underperformers:
            opportunities.append({
                'type': 'market_gap',
                'description': f"Found {len(underperformers)} underperforming channels",
                'potential_impact': 'high',
                'recommended_action': 'Target their audience with better content'
            })
        
        # Identify high-growth opportunities
        high_growth = [c for c in competitors if c.growth_rate > median_growth * 2]
        
        if high_growth:
            opportunities.append({
                'type': 'trending_niche',
                'description': f"Found {len(high_growth)} high-growth channels",
                'potential_impact': 'high',
                'recommended_action': 'Analyze and replicate their successful strategies'
            })
        
        return opportunities
    
    def _store_videos(self, videos: List[VideoData]):
        """Store video data in database"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        for video in videos:
            cursor.execute('''
            INSERT OR REPLACE INTO videos 
            (video_id, title, channel_id, channel_title, published_at, duration,
             view_count, like_count, comment_count, tags, category_id, description,
             engagement_rate, collected_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                video.video_id, video.title, video.channel_id, video.channel_title,
                video.published_at, video.duration, video.view_count, video.like_count,
                video.comment_count, json.dumps(video.tags), video.category_id,
                video.description, video.engagement_rate, datetime.now().isoformat()
            ))
        
        conn.commit()
        conn.close()
    
    def _store_channel(self, channel: ChannelData):
        """Store channel data in database"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
        INSERT OR REPLACE INTO channels
        (channel_id, title, subscriber_count, total_views, video_count,
         created_at, avg_views_per_video, growth_rate, last_updated)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            channel.channel_id, channel.title, channel.subscriber_count,
            channel.total_views, channel.video_count, channel.created_at,
            channel.avg_views_per_video, channel.growth_rate,
            datetime.now().isoformat()
        ))
        
        conn.commit()
        conn.close()
    
    def _store_trends(self, trends: List[Dict[str, Any]]):
        """Store trending topics in database"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        for trend in trends:
            cursor.execute('''
            INSERT INTO trends (keyword, trend_score, category, detected_at)
            VALUES (?, ?, ?, ?)
            ''', (
                trend['keyword'], trend['trend_score'],
                trend['category'], trend['detected_at']
            ))
        
        conn.commit()
        conn.close()
    
    def generate_data_report(self) -> Dict[str, Any]:
        """Generate a comprehensive data report"""
        conn = sqlite3.connect(self.db_path)
        
        # Get summary statistics
        video_count = pd.read_sql_query('SELECT COUNT(*) as count FROM videos', conn).iloc[0]['count']
        channel_count = pd.read_sql_query('SELECT COUNT(*) as count FROM channels', conn).iloc[0]['count']
        
        # Get top performing videos
        top_videos_query = '''
        SELECT title, channel_title, view_count, engagement_rate 
        FROM videos 
        ORDER BY view_count DESC 
        LIMIT 10
        '''
        top_videos = pd.read_sql_query(top_videos_query, conn)
        
        # Get recent trends
        recent_trends_query = '''
        SELECT keyword, trend_score 
        FROM trends 
        WHERE detected_at > datetime('now', '-7 days')
        ORDER BY trend_score DESC 
        LIMIT 10
        '''
        recent_trends = pd.read_sql_query(recent_trends_query, conn)
        
        conn.close()
        
        report = {
            'summary': {
                'total_videos_analyzed': int(video_count),
                'total_channels_analyzed': int(channel_count),
                'report_generated': datetime.now().isoformat()
            },
            'top_performing_videos': top_videos.to_dict('records') if not top_videos.empty else [],
            'trending_topics': recent_trends.to_dict('records') if not recent_trends.empty else []
        }
        
        logger.info("‚úÖ Data report generated")
        return report


def main():
    """Demonstration of real YouTube data collection"""
    # This would use your actual YouTube API key
    API_KEY = os.getenv('YOUTUBE_API_KEY')
    
    if not API_KEY:
        print("‚ùå Please set YOUTUBE_API_KEY environment variable")
        return
    
    collector = RealYouTubeCollector(API_KEY)
    
    print("\nüìä REAL YOUTUBE DATA COLLECTOR DEMONSTRATION")
    print("=" * 60)
    
    # Get trending videos
    print("\nüî• Collecting trending videos...")
    trending = collector.get_trending_videos(max_results=10)
    print(f"‚úÖ Collected {len(trending)} trending videos")
    
    # Search for specific keyword
    print("\nüîç Searching for 'AI' videos...")
    ai_videos = collector.search_videos_by_keyword("artificial intelligence", max_results=10)
    print(f"‚úÖ Found {len(ai_videos)} AI-related videos")
    
    # Detect trending topics
    print("\nüìà Detecting trending topics...")
    topics = collector.detect_trending_topics()
    print(f"‚úÖ Detected {len(topics)} trending topics")
    
    # Generate report
    print("\nüìã Generating data report...")
    report = collector.generate_data_report()
    print(f"‚úÖ Report generated with {report['summary']['total_videos_analyzed']} videos")
    
    return collector, report


if __name__ == "__main__":
    main()
